{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data processing","metadata":{}},{"cell_type":"code","source":"%%capture\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nbase_path='/kaggle/input/asl-fingerspelling/'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-12T14:34:12.094868Z","iopub.execute_input":"2023-08-12T14:34:12.095455Z","iopub.status.idle":"2023-08-12T14:34:12.110048Z","shell.execute_reply.started":"2023-08-12T14:34:12.095404Z","shell.execute_reply":"2023-08-12T14:34:12.108307Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport json\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm.notebook import tqdm\nimport re\nfrom scipy.stats import skew, kurtosis\nimport warnings\n\n#warnings.filterwarnings(\"ignore\", message=\"NumPy version\")","metadata":{"execution":{"iopub.status.busy":"2023-08-12T14:34:12.120067Z","iopub.execute_input":"2023-08-12T14:34:12.121679Z","iopub.status.idle":"2023-08-12T14:34:12.130220Z","shell.execute_reply.started":"2023-08-12T14:34:12.121606Z","shell.execute_reply":"2023-08-12T14:34:12.128839Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"DEBUG = True","metadata":{"execution":{"iopub.status.busy":"2023-08-12T14:34:12.133086Z","iopub.execute_input":"2023-08-12T14:34:12.134200Z","iopub.status.idle":"2023-08-12T14:34:12.143571Z","shell.execute_reply.started":"2023-08-12T14:34:12.134133Z","shell.execute_reply":"2023-08-12T14:34:12.142242Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_path=f'{base_path}/train.csv'\ntrain = pd.read_csv(train_path).head(10) if DEBUG else pd.read_csv(file_path)\ntrain","metadata":{"execution":{"iopub.status.busy":"2023-08-12T14:34:12.185715Z","iopub.execute_input":"2023-08-12T14:34:12.186714Z","iopub.status.idle":"2023-08-12T14:34:12.324131Z","shell.execute_reply.started":"2023-08-12T14:34:12.186634Z","shell.execute_reply":"2023-08-12T14:34:12.322678Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                              path  file_id  sequence_id  participant_id  \\\n0  train_landmarks/5414471.parquet  5414471   1816796431             217   \n1  train_landmarks/5414471.parquet  5414471   1816825349             107   \n2  train_landmarks/5414471.parquet  5414471   1816909464               1   \n\n                phrase  \n0         3 creekhouse  \n1      scales/kuhaylah  \n2  1383 william lanier  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>file_id</th>\n      <th>sequence_id</th>\n      <th>participant_id</th>\n      <th>phrase</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_landmarks/5414471.parquet</td>\n      <td>5414471</td>\n      <td>1816796431</td>\n      <td>217</td>\n      <td>3 creekhouse</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_landmarks/5414471.parquet</td>\n      <td>5414471</td>\n      <td>1816825349</td>\n      <td>107</td>\n      <td>scales/kuhaylah</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_landmarks/5414471.parquet</td>\n      <td>5414471</td>\n      <td>1816909464</td>\n      <td>1</td>\n      <td>1383 william lanier</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train['phrase_char'] = train['phrase'].apply(tuple)\ntrain['phrase_char_len'] = train['phrase_char'].apply(len)\n\ntrain_sequence_id = train.set_index('sequence_id')\n\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-12T14:34:12.327606Z","iopub.execute_input":"2023-08-12T14:34:12.328383Z","iopub.status.idle":"2023-08-12T14:34:12.354356Z","shell.execute_reply.started":"2023-08-12T14:34:12.328319Z","shell.execute_reply":"2023-08-12T14:34:12.352465Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"                              path  file_id  sequence_id  participant_id  \\\n0  train_landmarks/5414471.parquet  5414471   1816796431             217   \n1  train_landmarks/5414471.parquet  5414471   1816825349             107   \n2  train_landmarks/5414471.parquet  5414471   1816909464               1   \n\n                phrase                                        phrase_char  \\\n0         3 creekhouse               (3,  , c, r, e, e, k, h, o, u, s, e)   \n1      scales/kuhaylah      (s, c, a, l, e, s, /, k, u, h, a, y, l, a, h)   \n2  1383 william lanier  (1, 3, 8, 3,  , w, i, l, l, i, a, m,  , l, a, ...   \n\n   phrase_char_len  \n0               12  \n1               15  \n2               19  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>file_id</th>\n      <th>sequence_id</th>\n      <th>participant_id</th>\n      <th>phrase</th>\n      <th>phrase_char</th>\n      <th>phrase_char_len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_landmarks/5414471.parquet</td>\n      <td>5414471</td>\n      <td>1816796431</td>\n      <td>217</td>\n      <td>3 creekhouse</td>\n      <td>(3,  , c, r, e, e, k, h, o, u, s, e)</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_landmarks/5414471.parquet</td>\n      <td>5414471</td>\n      <td>1816825349</td>\n      <td>107</td>\n      <td>scales/kuhaylah</td>\n      <td>(s, c, a, l, e, s, /, k, u, h, a, y, l, a, h)</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_landmarks/5414471.parquet</td>\n      <td>5414471</td>\n      <td>1816909464</td>\n      <td>1</td>\n      <td>1383 william lanier</td>\n      <td>(1, 3, 8, 3,  , w, i, l, l, i, a, m,  , l, a, ...</td>\n      <td>19</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"with open(base_path+'character_to_prediction_index.json') as json_file:\n    CHAR2ORD = json.load(json_file)\n\nCHAR2ORD_df=pd.Series(CHAR2ORD).to_frame('Ordinal Encoding')\nprint(type(CHAR2ORD),type(CHAR2ORD_df))\n\n\ndef encode_phrase(phrase):\n    # .get(char, -1): if the char doesn't exist in dict, return -1.\n    return [CHAR2ORD.get(char, -1) for char in phrase]\n\ntrain['ordinal_encoding'] = train['phrase'].apply(encode_phrase)\n\ntrain.head()\n","metadata":{"execution":{"iopub.status.busy":"2023-08-12T14:34:12.356146Z","iopub.execute_input":"2023-08-12T14:34:12.356673Z","iopub.status.idle":"2023-08-12T14:34:12.387844Z","shell.execute_reply.started":"2023-08-12T14:34:12.356631Z","shell.execute_reply":"2023-08-12T14:34:12.386403Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"<class 'dict'> <class 'pandas.core.frame.DataFrame'>\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"                              path  file_id  sequence_id  participant_id  \\\n0  train_landmarks/5414471.parquet  5414471   1816796431             217   \n1  train_landmarks/5414471.parquet  5414471   1816825349             107   \n2  train_landmarks/5414471.parquet  5414471   1816909464               1   \n\n                phrase                                        phrase_char  \\\n0         3 creekhouse               (3,  , c, r, e, e, k, h, o, u, s, e)   \n1      scales/kuhaylah      (s, c, a, l, e, s, /, k, u, h, a, y, l, a, h)   \n2  1383 william lanier  (1, 3, 8, 3,  , w, i, l, l, i, a, m,  , l, a, ...   \n\n   phrase_char_len                                   ordinal_encoding  \n0               12    [18, 0, 34, 49, 36, 36, 42, 39, 46, 52, 50, 36]  \n1               15  [50, 34, 32, 43, 36, 50, 14, 42, 52, 39, 32, 5...  \n2               19  [16, 18, 23, 18, 0, 54, 40, 43, 43, 40, 32, 44...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>file_id</th>\n      <th>sequence_id</th>\n      <th>participant_id</th>\n      <th>phrase</th>\n      <th>phrase_char</th>\n      <th>phrase_char_len</th>\n      <th>ordinal_encoding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_landmarks/5414471.parquet</td>\n      <td>5414471</td>\n      <td>1816796431</td>\n      <td>217</td>\n      <td>3 creekhouse</td>\n      <td>(3,  , c, r, e, e, k, h, o, u, s, e)</td>\n      <td>12</td>\n      <td>[18, 0, 34, 49, 36, 36, 42, 39, 46, 52, 50, 36]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_landmarks/5414471.parquet</td>\n      <td>5414471</td>\n      <td>1816825349</td>\n      <td>107</td>\n      <td>scales/kuhaylah</td>\n      <td>(s, c, a, l, e, s, /, k, u, h, a, y, l, a, h)</td>\n      <td>15</td>\n      <td>[50, 34, 32, 43, 36, 50, 14, 42, 52, 39, 32, 5...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_landmarks/5414471.parquet</td>\n      <td>5414471</td>\n      <td>1816909464</td>\n      <td>1</td>\n      <td>1383 william lanier</td>\n      <td>(1, 3, 8, 3,  , w, i, l, l, i, a, m,  , l, a, ...</td>\n      <td>19</td>\n      <td>[16, 18, 23, 18, 0, 54, 40, 43, 43, 40, 32, 44...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Add complete file path to train\ndef get_file_path(path):\n    return f'{base_path}{path}'\n\ntrain['file_path'] = train['path'].apply(get_file_path)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-12T14:34:12.390958Z","iopub.execute_input":"2023-08-12T14:34:12.391616Z","iopub.status.idle":"2023-08-12T14:34:12.415464Z","shell.execute_reply.started":"2023-08-12T14:34:12.391559Z","shell.execute_reply":"2023-08-12T14:34:12.413915Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"                              path  file_id  sequence_id  participant_id  \\\n0  train_landmarks/5414471.parquet  5414471   1816796431             217   \n1  train_landmarks/5414471.parquet  5414471   1816825349             107   \n2  train_landmarks/5414471.parquet  5414471   1816909464               1   \n\n                phrase                                        phrase_char  \\\n0         3 creekhouse               (3,  , c, r, e, e, k, h, o, u, s, e)   \n1      scales/kuhaylah      (s, c, a, l, e, s, /, k, u, h, a, y, l, a, h)   \n2  1383 william lanier  (1, 3, 8, 3,  , w, i, l, l, i, a, m,  , l, a, ...   \n\n   phrase_char_len                                   ordinal_encoding  \\\n0               12    [18, 0, 34, 49, 36, 36, 42, 39, 46, 52, 50, 36]   \n1               15  [50, 34, 32, 43, 36, 50, 14, 42, 52, 39, 32, 5...   \n2               19  [16, 18, 23, 18, 0, 54, 40, 43, 43, 40, 32, 44...   \n\n                                           file_path  \n0  /kaggle/input/asl-fingerspelling/train_landmar...  \n1  /kaggle/input/asl-fingerspelling/train_landmar...  \n2  /kaggle/input/asl-fingerspelling/train_landmar...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>file_id</th>\n      <th>sequence_id</th>\n      <th>participant_id</th>\n      <th>phrase</th>\n      <th>phrase_char</th>\n      <th>phrase_char_len</th>\n      <th>ordinal_encoding</th>\n      <th>file_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_landmarks/5414471.parquet</td>\n      <td>5414471</td>\n      <td>1816796431</td>\n      <td>217</td>\n      <td>3 creekhouse</td>\n      <td>(3,  , c, r, e, e, k, h, o, u, s, e)</td>\n      <td>12</td>\n      <td>[18, 0, 34, 49, 36, 36, 42, 39, 46, 52, 50, 36]</td>\n      <td>/kaggle/input/asl-fingerspelling/train_landmar...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_landmarks/5414471.parquet</td>\n      <td>5414471</td>\n      <td>1816825349</td>\n      <td>107</td>\n      <td>scales/kuhaylah</td>\n      <td>(s, c, a, l, e, s, /, k, u, h, a, y, l, a, h)</td>\n      <td>15</td>\n      <td>[50, 34, 32, 43, 36, 50, 14, 42, 52, 39, 32, 5...</td>\n      <td>/kaggle/input/asl-fingerspelling/train_landmar...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_landmarks/5414471.parquet</td>\n      <td>5414471</td>\n      <td>1816909464</td>\n      <td>1</td>\n      <td>1383 william lanier</td>\n      <td>(1, 3, 8, 3,  , w, i, l, l, i, a, m,  , l, a, ...</td>\n      <td>19</td>\n      <td>[16, 18, 23, 18, 0, 54, 40, 43, 43, 40, 32, 44...</td>\n      <td>/kaggle/input/asl-fingerspelling/train_landmar...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def get_phrase_type(phrase):\n    if re.match(r'^[\\d+-]+$', phrase):\n        return 'phone_number'\n    elif any([substr in phrase for substr in ['www', '.', '/']]) and ' ' not in phrase:\n        return 'url'\n    else:\n        return 'address'\n    \ntrain['phrase_type'] = train['phrase'].apply(get_phrase_type)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-12T14:34:12.426823Z","iopub.execute_input":"2023-08-12T14:34:12.427381Z","iopub.status.idle":"2023-08-12T14:34:12.453951Z","shell.execute_reply.started":"2023-08-12T14:34:12.427338Z","shell.execute_reply":"2023-08-12T14:34:12.452450Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                              path  file_id  sequence_id  participant_id  \\\n0  train_landmarks/5414471.parquet  5414471   1816796431             217   \n1  train_landmarks/5414471.parquet  5414471   1816825349             107   \n2  train_landmarks/5414471.parquet  5414471   1816909464               1   \n\n                phrase                                        phrase_char  \\\n0         3 creekhouse               (3,  , c, r, e, e, k, h, o, u, s, e)   \n1      scales/kuhaylah      (s, c, a, l, e, s, /, k, u, h, a, y, l, a, h)   \n2  1383 william lanier  (1, 3, 8, 3,  , w, i, l, l, i, a, m,  , l, a, ...   \n\n   phrase_char_len                                   ordinal_encoding  \\\n0               12    [18, 0, 34, 49, 36, 36, 42, 39, 46, 52, 50, 36]   \n1               15  [50, 34, 32, 43, 36, 50, 14, 42, 52, 39, 32, 5...   \n2               19  [16, 18, 23, 18, 0, 54, 40, 43, 43, 40, 32, 44...   \n\n                                           file_path phrase_type  \n0  /kaggle/input/asl-fingerspelling/train_landmar...     address  \n1  /kaggle/input/asl-fingerspelling/train_landmar...         url  \n2  /kaggle/input/asl-fingerspelling/train_landmar...     address  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>file_id</th>\n      <th>sequence_id</th>\n      <th>participant_id</th>\n      <th>phrase</th>\n      <th>phrase_char</th>\n      <th>phrase_char_len</th>\n      <th>ordinal_encoding</th>\n      <th>file_path</th>\n      <th>phrase_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_landmarks/5414471.parquet</td>\n      <td>5414471</td>\n      <td>1816796431</td>\n      <td>217</td>\n      <td>3 creekhouse</td>\n      <td>(3,  , c, r, e, e, k, h, o, u, s, e)</td>\n      <td>12</td>\n      <td>[18, 0, 34, 49, 36, 36, 42, 39, 46, 52, 50, 36]</td>\n      <td>/kaggle/input/asl-fingerspelling/train_landmar...</td>\n      <td>address</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_landmarks/5414471.parquet</td>\n      <td>5414471</td>\n      <td>1816825349</td>\n      <td>107</td>\n      <td>scales/kuhaylah</td>\n      <td>(s, c, a, l, e, s, /, k, u, h, a, y, l, a, h)</td>\n      <td>15</td>\n      <td>[50, 34, 32, 43, 36, 50, 14, 42, 52, 39, 32, 5...</td>\n      <td>/kaggle/input/asl-fingerspelling/train_landmar...</td>\n      <td>url</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_landmarks/5414471.parquet</td>\n      <td>5414471</td>\n      <td>1816909464</td>\n      <td>1</td>\n      <td>1383 william lanier</td>\n      <td>(1, 3, 8, 3,  , w, i, l, l, i, a, m,  , l, a, ...</td>\n      <td>19</td>\n      <td>[16, 18, 23, 18, 0, 54, 40, 43, 43, 40, 32, 44...</td>\n      <td>/kaggle/input/asl-fingerspelling/train_landmar...</td>\n      <td>address</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"%%time\ndef process_landmarks(file_path, debug=False):\n    landmarks = pd.read_parquet(file_path)\n    #print(landmarks.info())\n    #return\n    \n\n\n    processed_landmarks_list = []\n    for seq_id in tqdm(landmarks.index.unique()):\n        '''*** Use [[]] to make sure it's a DataFrame but not Series !!!!\n        Otherwise, if there are multiple rows that match the label, a DataFrame will be returned;\n        If there is only one row that matches the label, return a Series'''\n        sequence = landmarks.loc[[seq_id]].copy() \n        #print(type(sequence))\n        #return\n        #print(f\"Processing sequence_id: {seq_id}\")\n        #print(sequence.head())\n        \n#         if debug and len(processed_landmarks_list) >= 5:\n#             break\n    \n        # Deal with NaN\n        coordinate_columns = [col for col in sequence.columns if col.startswith(('x_', 'y_', 'z_'))]\n        sequence.loc[:, coordinate_columns] = sequence[coordinate_columns].fillna(0.0)\n        \n        sequence['sequence_id'] = seq_id\n\n        # Others..unfinished....\n        # ...\n\n        processed_landmarks_list.append(sequence)\n\n    processed_landmarks = pd.concat(processed_landmarks_list, ignore_index=True)\n    return processed_landmarks\n\n\nprocessed_landmarks_list = [process_landmarks(file_path, debug=DEBUG) for file_path in tqdm(train['file_path'])]\n\nall_processed_landmarks = pd.concat(processed_landmarks_list, ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-12T14:34:12.462219Z","iopub.execute_input":"2023-08-12T14:34:12.463263Z","iopub.status.idle":"2023-08-12T14:37:46.690324Z","shell.execute_reply.started":"2023-08-12T14:34:12.463216Z","shell.execute_reply":"2023-08-12T14:37:46.688805Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d5c8710ab2443f58cc2c968397e7e11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1db9578bb13347ec92b770c000f5ab4e"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","File \u001b[0;32m<timed exec>:36\u001b[0m\n","File \u001b[0;32m<timed exec>:36\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n","File \u001b[0;32m<timed exec>:23\u001b[0m, in \u001b[0;36mprocess_landmarks\u001b[0;34m(file_path, debug)\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexing.py:818\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    817\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[0;32m--> 818\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexing.py:1795\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1792\u001b[0m \u001b[38;5;66;03m# align and set the values\u001b[39;00m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m take_split_path:\n\u001b[1;32m   1794\u001b[0m     \u001b[38;5;66;03m# We have to operate column-wise\u001b[39;00m\n\u001b[0;32m-> 1795\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_split_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1796\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1797\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_block(indexer, value, name)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexing.py:1831\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like_indexer(value) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1830\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, ABCDataFrame):\n\u001b[0;32m-> 1831\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_frame_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1833\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(value) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   1834\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_with_indexer_2d_value(indexer, value)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexing.py:1949\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_frame_value\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m value:\n\u001b[1;32m   1948\u001b[0m     sub_indexer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m item\n\u001b[0;32m-> 1949\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_align_series\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1950\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msub_indexer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultiindex_indexer\u001b[49m\n\u001b[1;32m   1951\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1953\u001b[0m     val \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexing.py:2274\u001b[0m, in \u001b[0;36m_iLocIndexer._align_series\u001b[0;34m(self, indexer, ser, multiindex_indexer)\u001b[0m\n\u001b[1;32m   2272\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2273\u001b[0m     new_ix \u001b[38;5;241m=\u001b[39m Index(new_ix)\n\u001b[0;32m-> 2274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mequals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_ix\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(new_ix):\n\u001b[1;32m   2275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ser\u001b[38;5;241m.\u001b[39m_values\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m   2277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ser\u001b[38;5;241m.\u001b[39mreindex(new_ix)\u001b[38;5;241m.\u001b[39m_values\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:5549\u001b[0m, in \u001b[0;36mIndex.equals\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   5545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_extension_array_dtype(other\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m   5546\u001b[0m     \u001b[38;5;66;03m# All EA-backed Index subclasses override equals\u001b[39;00m\n\u001b[1;32m   5547\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m other\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 5549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray_equivalent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/dtypes/missing.py:553\u001b[0m, in \u001b[0;36marray_equivalent\u001b[0;34m(left, right, strict_nan, dtype_equal)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    549\u001b[0m     left\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;129;01mis\u001b[39;00m np\u001b[38;5;241m.\u001b[39mvoid \u001b[38;5;129;01mor\u001b[39;00m right\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;129;01mis\u001b[39;00m np\u001b[38;5;241m.\u001b[39mvoid\n\u001b[1;32m    550\u001b[0m ) \u001b[38;5;129;01mand\u001b[39;00m left\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m right\u001b[38;5;241m.\u001b[39mdtype:\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 553\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_equal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36marray_equal\u001b[0;34m(*args, **kwargs)\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/numeric.py:2463\u001b[0m, in \u001b[0;36marray_equal\u001b[0;34m(a1, a2, equal_nan)\u001b[0m\n\u001b[1;32m   2461\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m equal_nan:\n\u001b[0;32m-> 2463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ma2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2464\u001b[0m \u001b[38;5;66;03m# Handling NaN values if equal_nan is True\u001b[39;00m\n\u001b[1;32m   2465\u001b[0m a1nan, a2nan \u001b[38;5;241m=\u001b[39m isnan(a1), isnan(a2)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:63\u001b[0m, in \u001b[0;36m_all\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_all\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# Parsing keyword arguments is currently fairly slow, so avoid it for now\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_all(a, axis, dtype, out, keepdims, where\u001b[38;5;241m=\u001b[39mwhere)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"all_processed_landmarks.tail()","metadata":{"execution":{"iopub.status.busy":"2023-08-12T14:37:46.692560Z","iopub.execute_input":"2023-08-12T14:37:46.692986Z","iopub.status.idle":"2023-08-12T14:37:46.735202Z","shell.execute_reply.started":"2023-08-12T14:37:46.692950Z","shell.execute_reply":"2023-08-12T14:37:46.732978Z"},"trusted":true},"execution_count":20,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mall_processed_landmarks\u001b[49m\u001b[38;5;241m.\u001b[39mtail()\n","\u001b[0;31mNameError\u001b[0m: name 'all_processed_landmarks' is not defined"],"ename":"NameError","evalue":"name 'all_processed_landmarks' is not defined","output_type":"error"}]},{"cell_type":"code","source":"columns = all_processed_landmarks.columns\n\nparts = set()\n\nfor col in columns:\n    if '_' in col:\n        part_name = '_'.join(col.split('_')[1:-1])\n        if len(part_name)>0:\n            parts.add(part_name)\n\nparts_list = list(parts)\nprint(parts_list)","metadata":{"execution":{"iopub.status.busy":"2023-08-12T14:37:46.736104Z","iopub.status.idle":"2023-08-12T14:37:46.736576Z","shell.execute_reply.started":"2023-08-12T14:37:46.736373Z","shell.execute_reply":"2023-08-12T14:37:46.736394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(list(all_processed_landmarks.iterrows())))\nhas_nan = all_processed_landmarks.isna().any()\ncolumns_with_nan = has_nan[has_nan].index.tolist()\nprint(\"Columns with NaN values:\", columns_with_nan)","metadata":{"execution":{"iopub.status.busy":"2023-08-12T14:37:46.738435Z","iopub.status.idle":"2023-08-12T14:37:46.738958Z","shell.execute_reply.started":"2023-08-12T14:37:46.738744Z","shell.execute_reply":"2023-08-12T14:37:46.738767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfinal_coordinates_list = []\n\nfor row_index, frame in tqdm(all_processed_landmarks.iterrows()):\n#     if DEBUG and len(final_coordinates_list) >= 1000:\n#         break\n    for part_name in parts_list:\n        max_index = max(int(col.split('_')[-1]) for col in columns if f'x_{part_name}_' in col)\n        for index in range(max_index + 1):\n            temp_coordinates = {\n                'sequence_id': int(frame['sequence_id']),\n                'frame': int(frame['frame']),\n                'part': part_name,\n                'index': index,\n                'x': frame[f'x_{part_name}_{index}'],\n                'y': frame[f'y_{part_name}_{index}'],\n                'z': frame[f'z_{part_name}_{index}'],\n            }\n            final_coordinates_list.append(temp_coordinates)\n\nnew_df = pd.DataFrame(final_coordinates_list)","metadata":{"execution":{"iopub.status.busy":"2023-08-12T14:37:46.739951Z","iopub.status.idle":"2023-08-12T14:37:46.740381Z","shell.execute_reply.started":"2023-08-12T14:37:46.740145Z","shell.execute_reply":"2023-08-12T14:37:46.740163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Just want to try--\n# Set MultiIndex\nnew_df.set_index(['part', 'index'], inplace=True)\n\nprint(new_df.loc[('right_hand', 20)])\nprint(new_df.loc[('pose')].head())\nnew_df.tail()\n\nnew_df.reset_index(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-12T14:37:46.741295Z","iopub.status.idle":"2023-08-12T14:37:46.741683Z","shell.execute_reply.started":"2023-08-12T14:37:46.741491Z","shell.execute_reply":"2023-08-12T14:37:46.741509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_df = pd.merge(train, new_df, on='sequence_id', how='left')\n\n#merged_df.query(\"part=='pose'\")\nmerged_df","metadata":{"execution":{"iopub.status.busy":"2023-08-12T14:37:46.744504Z","iopub.status.idle":"2023-08-12T14:37:46.745493Z","shell.execute_reply.started":"2023-08-12T14:37:46.745267Z","shell.execute_reply":"2023-08-12T14:37:46.745291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_df = pd.merge(train, all_processed_landmarks, on='sequence_id', how='left')\nmerged_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-12T14:37:46.746693Z","iopub.status.idle":"2023-08-12T14:37:46.747126Z","shell.execute_reply.started":"2023-08-12T14:37:46.746916Z","shell.execute_reply":"2023-08-12T14:37:46.746936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"', '.join(merged_df.columns)","metadata":{"execution":{"iopub.status.busy":"2023-08-12T14:37:46.748396Z","iopub.status.idle":"2023-08-12T14:37:46.748803Z","shell.execute_reply.started":"2023-08-12T14:37:46.748598Z","shell.execute_reply":"2023-08-12T14:37:46.748625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature cols\nfeatures = merged_df.drop(columns=['sequence_id', 'participant_id', 'phrase', 'phrase_char', 'phrase_char_len', 'phrase_type'])\n\n# Label cols\nlabels = final_data['ordinal_encoding']\n","metadata":{"execution":{"iopub.status.busy":"2023-08-12T14:37:46.750711Z","iopub.status.idle":"2023-08-12T14:37:46.751102Z","shell.execute_reply.started":"2023-08-12T14:37:46.750910Z","shell.execute_reply":"2023-08-12T14:37:46.750929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}